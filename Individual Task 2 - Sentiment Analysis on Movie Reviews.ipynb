{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie Reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Task 2. Yana Herman. Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\n",
    "\n",
    "import nltk\n",
    "\n",
    "import unicodedata, re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation & Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.tsv', '\\t')\n",
    "test = pd.read_csv('test.tsv', '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train.tsv contains the phrases and their associated sentiment labels. SentenceId helps to track which phrases belong to a single sentence.\n",
    "- test.tsv contains just phrases. You must assign a sentiment label to each phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (156060, 4)\n",
      "Test: (66292, 3)\n"
     ]
    }
   ],
   "source": [
    "#dataset shapes\n",
    "print(\"Train :\",train.shape)\n",
    "print(\"Test:\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for NULL or NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns[train.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns[test.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment labels are:\n",
    "\n",
    "- 0 - negative\n",
    "- 1 - somewhat negative\n",
    "- 2 - neutral\n",
    "- 3 - somewhat positive\n",
    "- 4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of phrases with sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = train.groupby([\"Sentiment\"]).size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.barplot( dist.keys(), dist.values, palette=\"rocket\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use words to create a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = train['Phrase'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-ASCII characters\n",
    "def remove_non_ascii(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "# All words to lowercase\n",
    "def to_lowercase(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "# Remove punctuation\n",
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "# Remove all numbers\n",
    "def remove_numbers(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(\"\\d+\", \"\", word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_numbers(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [a, series, of, escapades, demonstrating, the,...\n",
       "1    [a, series, of, escapades, demonstrating, the,...\n",
       "2                                          [a, series]\n",
       "3                                                  [a]\n",
       "4                                             [series]\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = words.apply(normalize) \n",
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of unique words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 values: \n",
      "\n",
      "sam, 1 \n",
      "devastated, 2 \n",
      "everyjokehas, 3 \n",
      "convenient, 4 \n",
      "giveandtake, 5 \n",
      "metropolitan, 6 \n",
      "masculine, 7 \n",
      "repulsive, 8 \n",
      "misfiring, 9 \n",
      "renegadecop, 10 \n",
      "restored, 11 \n",
      "wanted, 12 \n",
      "selfcontrol, 13 \n",
      "undisputed, 14 \n",
      "between, 15 \n",
      "blockbuster, 16 \n",
      "definitive, 17 \n",
      "enigma, 18 \n",
      "coarse, 19 \n",
      "morsels, 20 \n"
     ]
    }
   ],
   "source": [
    "word_set = set()\n",
    "for l in words:\n",
    "    for e in l:\n",
    "        word_set.add(e)\n",
    "        \n",
    "vocabulary = {word: ii for ii, word in enumerate(word_set, 1)}\n",
    "\n",
    "print (\"First 20 values: \\n\")\n",
    "\n",
    "for x in list(vocabulary)[0:20]:\n",
    "    print (\"{}, {} \".format(x,  vocabulary[x]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need tokens to create the feature matrix. Phrases are encoded according to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1330, 282, 10776, 5716, 9114, 2301, 11666, 10...\n",
       "1    [1330, 282, 10776, 5716, 9114, 2301, 11666, 10...\n",
       "2                                          [1330, 282]\n",
       "3                                               [1330]\n",
       "4                                                [282]\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = words.apply(lambda l: [vocabulary[word] for word in l])\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "array([[ 1330,   282, 10776, ...,     0,     0,     0],\n",
      "       [ 1330,   282, 10776, ...,     0,     0,     0],\n",
      "       [ 1330,   282,     0, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [ 6806, 13696,     0, ...,     0,     0,     0],\n",
      "       [ 6806,     0,     0, ...,     0,     0,     0],\n",
      "       [13696,     0,     0, ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# The longest phrase\n",
    "max_len = tokens.str.len().max()\n",
    "print(max_len)\n",
    "\n",
    "# Make all token arrays equal by adding zeros in the end\n",
    "all_tokens = np.array([t for t in tokens])\n",
    "features = np.zeros((len(all_tokens), max_len), dtype=int)\n",
    "for i, row in enumerate(all_tokens):\n",
    "    features[i, :len(row)] = row\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case correlation between features is not needed as the features do not influence each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertion to a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let 0-1 be negative (0) \n",
    "- Let 2-4 be positive (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "156055    1\n",
       "156056    0\n",
       "156057    1\n",
       "156058    1\n",
       "156059    1\n",
       "Name: Sentiment, Length: 156060, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train[\"Sentiment\"].apply(lambda i: 0 if i < 2 else 1)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Algorithm selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124848, 48), (124848,), (31212, 48), (31212,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size = 0.2, shuffle = True, stratify = target)\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "max_iters = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=max_iters, tol=1e-10)\n",
    "clf = clf.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = clf.predict(X_train)\n",
    "Y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results evaluation for training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77594\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted\t0\t1\n",
      "Actual\n",
      "0\t\t811\t26665\n",
      "1\t\t1308\t96064\n",
      "\n",
      "Precision: 0.78273\n",
      "\n",
      "Recall: 0.98657\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc_scr = accuracy_score(Y_train, Y_train_pred)\n",
    "print(\"Accuracy: {:.5f}\\n\".format(acc_scr))\n",
    "\n",
    "# Confusion Matrix:\n",
    "conf_mtrx = confusion_matrix(Y_train, Y_train_pred)\n",
    "print(\"Confusion Matrix:\\nPredicted\\t0\\t1\\nActual\\n0\\t\\t{}\\t{}\\n1\\t\\t{}\\t{}\".format(conf_mtrx[0][0], conf_mtrx[0][1],conf_mtrx[1][0],conf_mtrx[1][1]))\n",
    "\n",
    "# Precision\n",
    "prec = precision_score(Y_train, Y_train_pred)\n",
    "print(\"\\nPrecision: {:.5f}\".format(prec))\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(Y_train, Y_train_pred)\n",
    "print(\"\\nRecall: {:.5f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results evaluation for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77550\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted\t0\t1\n",
      "Actual\n",
      "0\t\t203\t6666\n",
      "1\t\t341\t24002\n",
      "\n",
      "Precision: 0.78264\n",
      "\n",
      "Recall: 0.98599\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc_scr = accuracy_score(Y_test, Y_test_pred)\n",
    "print(\"Accuracy: {:.5f}\\n\".format(acc_scr))\n",
    "\n",
    "# Confusion Matrix:\n",
    "conf_mtrx = confusion_matrix(Y_test, Y_test_pred)\n",
    "print(\"Confusion Matrix:\\nPredicted\\t0\\t1\\nActual\\n0\\t\\t{}\\t{}\\n1\\t\\t{}\\t{}\".format(conf_mtrx[0][0], conf_mtrx[0][1],conf_mtrx[1][0],conf_mtrx[1][1]))\n",
    "\n",
    "# Precision\n",
    "prec = precision_score(Y_test, Y_test_pred)\n",
    "print(\"\\nPrecision: {:.5f}\".format(prec))\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(Y_test, Y_test_pred)\n",
    "print(\"\\nRecall: {:.5f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Custom realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X_new = (X - mean) / std\n",
    "    return X_new, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X(X):\n",
    "    m = X.shape[0]\n",
    "    ones = np.ones((m, 1))\n",
    "    X_new = np.column_stack((ones, X))\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, theta):\n",
    "    z = np.dot(X, theta)\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    if m == 0:\n",
    "        return None\n",
    "    \n",
    "    J = (-y * np.log(h(X, theta)) - (1 - y) * np.log(1 - h(X, theta))).mean()\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_theta(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    if m == 0:\n",
    "        return None\n",
    "\n",
    "    d_theta = np.dot(X.T, (h(X, theta) - y)) / m\n",
    "    \n",
    "    return d_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, epsilon, num_iters, print_J = True):\n",
    "    m = X.shape[0]\n",
    "    J_history = []\n",
    "    \n",
    "    J = cost_function(X, y, theta)\n",
    "    \n",
    "    if print_J == True:\n",
    "        print(J)\n",
    "    J_history.append(J)\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        delta = derivative_theta(X, y, theta)\n",
    "        theta = theta - alpha * delta\n",
    "        \n",
    "        J = cost_function(X, y, theta)\n",
    "        \n",
    "        J_history.append(J)\n",
    "        \n",
    "        if i % 1000 == 0 and print_J == True:\n",
    "            print(J)\n",
    "        \n",
    "        if abs(J-J_history[-2]) < epsilon:\n",
    "            break\n",
    "            \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    X_test_proc = prepare_X(X)\n",
    "    predictions = h(X_test_proc, theta)\n",
    "    return predictions.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "max_iters = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, mean, std = normalize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_X(X_new)\n",
    "Y_new = Y_train.values.reshape((X_train.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#theta = np.zeros((X_new.shape[1], 1))\n",
    "theta = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "theta.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79750459  0.01528796 -0.01607344 -0.03650645 -0.04604581 -0.05069408\n",
      " -0.05822043 -0.05159691 -0.05128454 -0.04414079 -0.03996187 -0.03371325\n",
      " -0.01448071 -0.02782152 -0.00625814 -0.01170241 -0.02754767 -0.00653086\n",
      "  0.01056781  0.00787645 -0.02296424 -0.00182987 -0.01495654 -0.02720707\n",
      "  0.02197153  0.01966137 -0.00697156 -0.0309146   0.01862933  0.02427491\n",
      "  0.02805089  0.02238163  0.01113192 -0.02476146 -0.04357232 -0.04247165\n",
      " -0.05064778 -0.08448509 -0.09802828 -0.11567252 -0.15843851 -0.161316\n",
      " -0.19374451 -0.21389106 -0.22988661 -0.22991476 -0.2557413  -0.25210161\n",
      " -0.25549368] 8993\n"
     ]
    }
   ],
   "source": [
    "new_theta, Js = gradient_descent(X_new, Y_train, theta, alpha, 1e-7, max_iters, False)\n",
    "print(new_theta, len(Js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = predict(X_train, new_theta)\n",
    "print(Y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = predict(X_test, new_theta)\n",
    "print(Y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results evaluation for training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37674\n",
      "\n",
      "\tConfusion Matrix:\n",
      "Predicted    0.0    1.0\n",
      "Actual                 \n",
      "0          24182   3294\n",
      "1          74519  22853\n",
      "\n",
      "Precision: 0.87402\n",
      "\n",
      "Recall: 0.23470\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc_scr = accuracy_score(Y_train, Y_train_pred)\n",
    "print(\"Accuracy: {:.5f}\\n\".format(acc_scr))\n",
    "\n",
    "# Confusion Matrix:\n",
    "conf_mtrx = pd.crosstab(Y_train, Y_train_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"\\tConfusion Matrix:\\n{}\".format(conf_mtrx))\n",
    "\n",
    "# Precision\n",
    "prec = conf_mtrx[1][1]/(conf_mtrx[1][1] + conf_mtrx[1][0])\n",
    "print(\"\\nPrecision: {:.5f}\".format(prec))\n",
    "\n",
    "# Recall\n",
    "recall = conf_mtrx[1][1]/(conf_mtrx[1][1] + conf_mtrx[0][1])\n",
    "print(\"\\nRecall: {:.5f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results evaluation for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37364\n",
      "\n",
      "\tConfusion Matrix:\n",
      "Predicted    0.0   1.0\n",
      "Actual                \n",
      "0           5989   880\n",
      "1          18670  5673\n",
      "\n",
      "Precision: 0.86571\n",
      "\n",
      "Recall: 0.23304\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc_scr = accuracy_score(Y_test, Y_test_pred)\n",
    "print(\"Accuracy: {:.5f}\\n\".format(acc_scr))\n",
    "\n",
    "# Confusion Matrix:\n",
    "conf_mtrx = pd.crosstab(Y_test, Y_test_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"\\tConfusion Matrix:\\n{}\".format(conf_mtrx))\n",
    "\n",
    "# Precision\n",
    "prec = conf_mtrx[1][1]/(conf_mtrx[1][1] + conf_mtrx[1][0])\n",
    "print(\"\\nPrecision: {:.5f}\".format(prec))\n",
    "\n",
    "# Recall\n",
    "recall = conf_mtrx[1][1]/(conf_mtrx[1][1] + conf_mtrx[0][1])\n",
    "print(\"\\nRecall: {:.5f}\".format(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
